{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bac5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#Create and load dataset\n",
    "import h5py\n",
    "\n",
    "#SVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e92c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories and filepaths\n",
    "data_dir = Path(os.path.join(os.getcwd(),'data'))\n",
    "base_dir = Path(os.path.join(data_dir, \"state-farm-distracted-driver-detection\"))\n",
    "img_folder = Path(os.path.join(base_dir, 'imgs'))\n",
    "train_imgs = Path(os.path.join(img_folder, 'train'))\n",
    "test_imgs = Path(os.path.join(img_folder, 'test'))\n",
    "# load the image lists\n",
    "df = pd.read_csv(os.path.join(base_dir, 'driver_imgs_list.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e626107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5 filename \n",
    "\n",
    "# CHANGED FILENAMES TO INCLUDE GRAY OR COLOR \n",
    "#(THIS WILL BE A DIFF WITH THE LEAKAGE DATASETS THAT DIDNT HAVE DRIVER INFO)\n",
    "downscale = 2\n",
    "gray_scale=True\n",
    "if gray_scale:\n",
    "    hdf5_train = f\"StateFarm_Train_Gray_{downscale}X.h5\"\n",
    "else:\n",
    "    hdf5_train = f\"StateFarm_Train_Color_{downscale}X.h5\"\n",
    "\n",
    "if gray_scale:    \n",
    "    hdf5_test = f\"StateFarm_Test_Gray_{downscale}X.h5\"\n",
    "else:\n",
    "    hdf5_test = f\"StateFarm_Test_Color_{downscale}X.h5\"\n",
    "#\"StateFarm_Train_2X.h5\" # scaled down by 2\n",
    "#\"StateFarm_Train_5X.h5\" # scaled down by 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194d950",
   "metadata": {},
   "source": [
    "Functions to split on driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "str2int = lambda istr: int(re.findall('\\d+', istr)[0])\n",
    "\n",
    "def split_on_driver(df, train_split=.8,  seed=0):\n",
    "    # splits dataframe based on drivers\n",
    "    # take in dataframe (original), train_split proportion,  random seed\n",
    "    # returns new dataframe, train_drivers,  test_drivers\n",
    "    \n",
    "    # if dataframe doesn't already have driver, addit \n",
    "    if 'driver' not in df.columns:\n",
    "        df['driver'] =  df.subject.apply(str2int) # SID FOR SUBJECT ID\n",
    "        df['class'] = df.classname.apply(str2int) # \n",
    "   \n",
    "    # random number generator\n",
    "    rng = np.random.default_rng(seed=seed) \n",
    "    \n",
    "    # unique drivers and number of drivers\n",
    "    drivers = np.unique(df['driver'].values)\n",
    "    ndrivers = len(drivers)\n",
    "    \n",
    "    # number of data pts per driver \n",
    "    nPerDriver = df.groupby('driver').count().values\n",
    "    nPerDriver = nPerDriver[:,0]\n",
    "    \n",
    "    # shuffle drivers (get shuffle indices)\n",
    "    shuff_idx  = rng.permutation(ndrivers)\n",
    "    \n",
    "    # shuffle the drivers and the nPerDriver according to shuffle indices\n",
    "    drivers = drivers[shuff_idx]\n",
    "    nPerDriver = nPerDriver[shuff_idx]\n",
    "    \n",
    "    # separate drivers according to train_split\n",
    "    train_log = np.cumsum(nPerDriver) < (22424*train_split) # really close to 20/80 plit (e.g. splits at 17891, 80% is 17939)\n",
    "    test_log = np.logical_not(train_log)\n",
    "    train_drivers = drivers[train_log]\n",
    "    test_drivers = drivers[test_log]\n",
    "    \n",
    "    return (df, train_drivers, test_drivers, nPerDriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adbaf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set\n",
    "# load the dataframe\n",
    "df = pd.read_csv(os.path.join(base_dir, 'driver_imgs_list.csv'))\n",
    "# Open the HDF5 file\n",
    "file = h5py.File(data_dir / hdf5_train, \"r+\")\n",
    "images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "classes = np.array(file[\"/c\"]).astype(\"uint8\")\n",
    "drivers = np.array(file[\"/driver\"]).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c74261",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0b1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data matrix X \n",
    "image_size = images.shape\n",
    "# Resize images as vectors\n",
    "X = images.reshape(images.shape[0], images.shape[1]*images.shape[2])\n",
    "# Zero mean \n",
    "X = X - X.mean(axis=1).reshape(X.shape[0], 1)\n",
    "\n",
    "# split the training and validation data\n",
    "df, train_drivers, test_drivers, nPerDriver = split_on_driver(df, train_split=.8,  seed=0)\n",
    "train_log = [d in train_drivers for d in drivers]\n",
    "test_log = [d in test_drivers for d in drivers]\n",
    "\n",
    "Xtrain = X[train_log, ...]\n",
    "Ytrain = classes[train_log]\n",
    "\n",
    "Xval = X[test_log,...]\n",
    "Yval = classes[test_log] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a476ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using the parameters used before with the whole dataset\n",
    "mypca = PCA(n_components=160, whiten=True, random_state= 42)\n",
    "mysvm = SVC(C=5, gamma=0.01,kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(mypca, mysvm)\n",
    "# fit the model to trianing data\n",
    "history = model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd3c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict cross validation set\n",
    "ypred_val = model.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3d4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.54      0.32       471\n",
      "           1       0.81      0.25      0.38       452\n",
      "           2       0.99      0.18      0.30       485\n",
      "           3       0.60      0.47      0.52       475\n",
      "           4       0.97      0.08      0.14       479\n",
      "           5       0.90      0.94      0.92       489\n",
      "           6       0.95      0.42      0.58       474\n",
      "           7       0.97      0.57      0.72       401\n",
      "           8       0.19      0.83      0.30       393\n",
      "           9       0.73      0.13      0.22       432\n",
      "\n",
      "    accuracy                           0.43      4551\n",
      "   macro avg       0.73      0.44      0.44      4551\n",
      "weighted avg       0.74      0.43      0.44      4551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Yval, ypred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc05a5f",
   "metadata": {},
   "source": [
    "For 5x downscaled images (gray scale) <br>\n",
    "`mypca = PCA(n_components=160, whiten=True, random_state= 42)` <br>\n",
    "`mysvm = SVC(C=5, gamma=0.01,kernel='rbf', class_weight='balanced')`\n",
    " \n",
    " \n",
    " precision    recall  f1-score   support\n",
    "\n",
    "           0       0.24      0.47      0.32       471\n",
    "           1       0.75      0.22      0.34       452\n",
    "           2       0.99      0.16      0.27       485\n",
    "           3       0.67      0.41      0.51       475\n",
    "           4       1.00      0.07      0.13       479\n",
    "           5       0.88      0.89      0.89       489\n",
    "           6       0.97      0.32      0.49       474\n",
    "           7       0.72      0.55      0.62       401\n",
    "           8       0.16      0.85      0.28       393\n",
    "           9       0.78      0.19      0.30       432\n",
    "\n",
    "    accuracy                           0.41      4551\n",
    "`  macro avg       0.72      0.41      0.41      4551` <br>\n",
    "`weighted avg       0.73      0.41      0.42      4551` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The performance looks a lot worse now. How to improve it? \n",
    "# Phones are small, so it makes sense to use larger images.. Running again for 2x downscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e3c67",
   "metadata": {},
   "source": [
    "For 2x scaled images (same pars as above)\n",
    "   precision    recall  f1-score   support\n",
    "\n",
    "           0       0.22      0.54      0.32       471\n",
    "           1       0.81      0.25      0.38       452\n",
    "           2       0.99      0.18      0.30       485\n",
    "           3       0.60      0.47      0.52       475\n",
    "           4       0.97      0.08      0.14       479\n",
    "           5       0.90      0.94      0.92       489\n",
    "           6       0.95      0.42      0.58       474\n",
    "           7       0.97      0.57      0.72       401\n",
    "           8       0.19      0.83      0.30       393\n",
    "           9       0.73      0.13      0.22       432\n",
    "\n",
    "    accuracy                           0.43      4551 \n",
    "`   macro avg       0.73      0.44      0.44      4551`<br>\n",
    "`weighted avg       0.74      0.43      0.44      4551`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be66414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17873, 76800)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get a slight improvement from using a larger image, but it makes calculating the npcs harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9524f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try SV3M, first with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ca57518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from semisupervised import S3VM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0696207c",
   "metadata": {},
   "source": [
    "https://libraries.io/pypi/semisupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65161ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "random_unlabeled_points = rng.rand(len(Xtrain)) < 0.1\n",
    "\n",
    "Ytrain[random_unlabeled_points] = -1\n",
    "\n",
    "index, = np.where(Ytrain != -1)\n",
    "label_X_train = Xtrain[index,:]\n",
    "label_y_train = Ytrain[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0712ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index, = np.where(Ytrain == -1)\n",
    "unlabel_X_train = Xtrain[index,:]\n",
    "unlabel_y = -1*np.ones(unlabel_X_train.shape[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ba50017",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.2 GiB for an array with shape (17873, 76800) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12932/3578507739.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS3VM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabel_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabel_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fourthbrain\\lib\\site-packages\\semisupervised\\TSVM.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0munlabeledX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mlabeledX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mlabeledy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlabeledX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The number of unlabeled samples must larger than zero!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.2 GiB for an array with shape (17873, 76800) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = S3VM()\n",
    "model.fit(np.vstack((label_X_train, unlabel_X_train)), np.append(label_y_train, unlabel_y))\n",
    "# predict\n",
    "predict = model.predict(Xval)\n",
    "acc = metrics.accuracy_score(Yval, predict)\n",
    "# metric\n",
    "print(\"accuracy\", acc)\n",
    "print(classification_report(Yval, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91225ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1052/243250067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mxtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabel_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabel_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mself_training_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_training_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# let's try fitting with sklearn's version\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability=True, gamma=\"auto\")\n",
    "self_training_model = SelfTrainingClassifier(svc)\n",
    "\n",
    "xtrain = np.vstack((label_X_train, unlabel_X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865eb9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nemie\\anaconda3\\envs\\fourthbrain\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:187: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.2 GiB for an array with shape (17873, 76800) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1052/2989537913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munlabel_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mself_training_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_training_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fourthbrain\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         self.base_estimator_.fit(\n\u001b[1;32m--> 254\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msafe_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m             self.transduction_[has_label])\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.2 GiB for an array with shape (17873, 76800) and data type float64"
     ]
    }
   ],
   "source": [
    "ytrain = np.append(label_y_train, unlabel_y)\n",
    "\n",
    "self_training_model.fit(xtrain, ytrain)\n",
    "\n",
    "predict = self_training_model.predict(Xval)\n",
    "acc = metrics.accuracy_score(Yval, predict)\n",
    "# metric\n",
    "print(\"accuracy\", acc)\n",
    "print(classification_report(Yval, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d933d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fourthbrain",
   "language": "python",
   "name": "fourthbrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
