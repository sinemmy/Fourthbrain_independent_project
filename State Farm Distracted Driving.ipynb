{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef64eba7",
   "metadata": {},
   "source": [
    "### State Farm Distracted Driving: Classifying images based on driver safety\n",
    "\n",
    "See Also: https://www.kaggle.com/praveenmaripeti/state-farm-distracted-driver-detection-with-keras for NN implemntation with tensorflow\n",
    "\n",
    "Distracted driving causes a lot of accidents and is 100% preventable. Machine learning algorithms can gage driver safety using 2D dashboard camera images of drivers. The goal is to classify these images based on driver's behavior (cell phone, texting, etc). \n",
    "\n",
    "10 behaviors are classfied as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121f32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "#['c'+str(x) for x in range(10)]\n",
    "\n",
    "class_def = {'c0': 'safe driving',\n",
    "'c1': 'texting - right',\n",
    "'c2': 'talking on the phone - right',\n",
    "'c3': 'texting - left',\n",
    "'c4': 'talking on the phone - left',\n",
    "'c5': 'operating the radio',\n",
    "'c6': 'drinking',\n",
    "'c7': 'reaching behind',\n",
    "'c8': 'hair and makeup',\n",
    "'c9': 'talking to passenger'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248e7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant Libaries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#Create and load dataset\n",
    "import h5py\n",
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#SVM\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Learning Curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80c45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters for running the Notebook\n",
    "# hdf5 filename \n",
    "hdf5_train = \"StateFarm_Train.h5\"\n",
    "#write image dataset? \n",
    "write_dataset = False\n",
    "\n",
    "#run grid search for svm hyperparameters?\n",
    "run_gridsearch = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6662d8b",
   "metadata": {},
   "source": [
    "### Make and/or  Load HDF5 dataset (training data) :\n",
    "See: https://realpython.com/storing-images-in-python/\n",
    "and the [github Page](https://github.com/realpython/materials/blob/storing-images/storing-images/storing_images.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f432502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories and filepaths\n",
    "data_dir = Path(os.path.join(os.getcwd(),'data'))\n",
    "base_dir = Path(os.path.join(data_dir, \"state-farm-distracted-driver-detection\"))\n",
    "img_folder = Path(os.path.join(base_dir, 'imgs'))\n",
    "train_imgs = Path(os.path.join(img_folder, 'train'))\n",
    "test_imgs = Path(os.path.join(img_folder, 'test'))\n",
    "# load the image lists\n",
    "driver_imgs_list = pd.read_csv(os.path.join(base_dir, 'driver_imgs_list.csv'))\n",
    "sample_sub = pd.read_csv(os.path.join(base_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65df1412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head of image list\n",
    "driver_imgs_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dda9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image(filepath, resize_scale=2, gray_scale=True):\n",
    "  '''\n",
    "  Loads image, converts to grayscale, downsamples by resize_scale and returns a \n",
    "  To keep color image, set gray_scale = True \n",
    "  To keep the original size of the image, set resize_scale= 1\n",
    "  '''\n",
    "  im = Image.open(filepath)\n",
    "  if gray_scale:\n",
    "    im = im.convert('L')\n",
    "  if resize_scale > 1:\n",
    "    resize_dims = tuple([int(x/resize_scale) for x in (im.size)])\n",
    "    im = im.resize(resize_dims)\n",
    "  # makes array 1 X Px X Py for easier concatenation  \n",
    "  return np.array(im).reshape(1, np.array(im).shape[0], np.array(im).shape[1])\n",
    "\n",
    "if write_dataset: \n",
    "    # NOTE: USING NP ARRAYS IS MUCH SLOWER THAN DOING A LIST\n",
    "    # For training images data set (could probably parallelize this but...)\n",
    "    classnames = driver_imgs_list['classname'].values\n",
    "    labels = [int(x[1]) for x in classnames]\n",
    "    #filenames = driver_imgs_list['img'].values\n",
    "    image_list = [] # make a list, then concatenate\n",
    "    for i, file in enumerate(filenames):\n",
    "        if i%1000  == 0:    \n",
    "            print(f\"adding {file} to list, i={i}\") \n",
    "            \n",
    "        path_to_file = Path(os.path.join(train_imgs, labels[i], file))        \n",
    "        image_list.append(rescale_image(path_to_file, resize_scale = 2)) \n",
    "    # concatenate images into singe nd array  \n",
    "    images = np.concatenate(image_list, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c39445cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_dataset: \n",
    "    # each image is a row\n",
    "    # data = images.reshape(images.shape[0], images.shape[1]*images.shape[2])\n",
    "    \n",
    "    print('Writing HDF5 file')\n",
    "    # Create a new HDF5 file\n",
    "    file = h5py.File(\n",
    "        data_dir / hdf5_train, \"a\"\n",
    "    )\n",
    "\n",
    "    # Create a dataset in the file\n",
    "    image_set = file.create_dataset(\n",
    "        \"images\",\n",
    "        np.shape(images),\n",
    "        h5py.h5t.STD_U8BE,\n",
    "        data=images,\n",
    "    )\n",
    "    classnames_set = file.create_dataset(\n",
    "        \"labels\",\n",
    "        np.shape(labels),\n",
    "        h5py.h5t.STD_U8BE,\n",
    "        data=labels,\n",
    "    )    \n",
    "    \n",
    "    file.close()           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b7d71",
   "metadata": {},
   "source": [
    "Load hdf5 training dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60dffb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = [], []\n",
    "\n",
    "# Open the HDF5 file\n",
    "file = h5py.File(data_dir / hdf5_train, \"r+\")\n",
    "images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "labels = np.array(file[\"/labels\"]).astype(\"uint8\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e680130",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images.reshape(images.shape[0], images.shape[1]*images.shape[2])\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a363c",
   "metadata": {},
   "source": [
    "Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e8fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xcv, ytrain, ycv = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb64f69",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466cda73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate pipeline (using parameters from week 2: 2_4 Support Vector Machines to start)\n",
    "mypca = PCA(n_components=150, whiten=True, random_state= 42)\n",
    "mysvm = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(mypca, mysvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63634bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88086 (+/-0.00262) for {'svc__C': 1, 'svc__gamma': 0.0001}\n",
      "0.94177 (+/-0.00371) for {'svc__C': 1, 'svc__gamma': 0.0005}\n",
      "0.96292 (+/-0.00214) for {'svc__C': 1, 'svc__gamma': 0.001}\n",
      "0.99051 (+/-0.00013) for {'svc__C': 1, 'svc__gamma': 0.005}\n",
      "0.99363 (+/-0.00053) for {'svc__C': 1, 'svc__gamma': 0.01}\n",
      "0.93578 (+/-0.00569) for {'svc__C': 5, 'svc__gamma': 0.0001}\n",
      "0.96955 (+/-0.00149) for {'svc__C': 5, 'svc__gamma': 0.0005}\n",
      "0.98006 (+/-0.00124) for {'svc__C': 5, 'svc__gamma': 0.001}\n",
      "0.99427 (+/-0.00045) for {'svc__C': 5, 'svc__gamma': 0.005}\n",
      "0.99452 (+/-0.00051) for {'svc__C': 5, 'svc__gamma': 0.01}\n",
      "0.95094 (+/-0.00298) for {'svc__C': 10, 'svc__gamma': 0.0001}\n",
      "0.97490 (+/-0.00175) for {'svc__C': 10, 'svc__gamma': 0.0005}\n",
      "0.98496 (+/-0.00148) for {'svc__C': 10, 'svc__gamma': 0.001}\n",
      "0.99433 (+/-0.00037) for {'svc__C': 10, 'svc__gamma': 0.005}\n",
      "0.99452 (+/-0.00051) for {'svc__C': 10, 'svc__gamma': 0.01}\n",
      "0.96693 (+/-0.00231) for {'svc__C': 50, 'svc__gamma': 0.0001}\n",
      "0.98324 (+/-0.00117) for {'svc__C': 50, 'svc__gamma': 0.0005}\n",
      "0.98821 (+/-0.00165) for {'svc__C': 50, 'svc__gamma': 0.001}\n",
      "0.99427 (+/-0.00040) for {'svc__C': 50, 'svc__gamma': 0.005}\n",
      "0.99452 (+/-0.00051) for {'svc__C': 50, 'svc__gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "if run_gridsearch:\n",
    "    param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005, .01]}\n",
    "    # Instantiate the grid search with the model and parameter grid\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "    grid.fit(xtrain, ytrain)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "    #print(grid.cv_results_)\n",
    "    \n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    for mean, std, param in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.5f (+/-%0.05f) for %r\"\n",
    "              % (mean, std, param))\n",
    "    # STILL WANNA PICK 0.99433 (+/-0.00037) for {'svc__C': 10, 'svc__gamma': 0.005} (SMALLER STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad19adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH PICKED PARAMETERS: \n",
    "mypca = PCA(n_components=150, whiten=True, random_state= 42)\n",
    "mysvm = SVC(kernel='rbf', C=10, gamma=0.005, class_weight='balanced')\n",
    "model = make_pipeline(mypca, mysvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fourthbrain",
   "language": "python",
   "name": "fourthbrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
